{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/output/kaggle/working'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-14T23:51:26.286126Z","iopub.execute_input":"2021-12-14T23:51:26.286662Z","iopub.status.idle":"2021-12-14T23:51:26.291517Z","shell.execute_reply.started":"2021-12-14T23:51:26.286626Z","shell.execute_reply":"2021-12-14T23:51:26.290663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ntf.test.is_gpu_available()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy import array\nfrom numpy import argmax\nfrom pandas import DataFrame\nfrom nltk.translate.bleu_score import corpus_bleu\nfrom pickle import load\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.utils import plot_model\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import RepeatVector\nfrom keras.layers import TimeDistributed\nfrom keras.layers import Embedding\nfrom keras.layers.merge import add\nfrom keras.layers import Dropout\nfrom numpy import argmax\nfrom pickle import load\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import load_model\nfrom nltk.translate.bleu_score import corpus_bleu","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from os import listdir\nfrom pickle import dump\nfrom keras.applications.vgg16 import VGG16\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.models import Model\n\n# Image Extraction using VGG: \n\n# extract features \n\ndef features_extraction(path,valid_files):\n\t# loading the VGG pre-trained model\n\tmodel = VGG16()\n\t# re-structuring the model, removing last layer from the model\n\tmodel.layers.pop()\n\tmodel = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n\tprint(model.summary())\n\t# extracting features from each photo\n\tfeatures = dict()\n\tfor word in listdir(path):\n\t\t# loading a single image from file\n\t\tfile = path + '/' + word\n\t\t# if word == 'indian_wedding_Image_19.png':\n\t\t# print(word)\n\t\tif word not in valid_files:\n\t\t\tprint(word)\n\t\t\tcontinue\n\t\t#print(\"found\")\n\t\timg = load_img(file, target_size=(224, 224))\n\t\t# convering the image pixel to array\n\t\timg = img_to_array(img)\n\t\t# reshape\n\t\timg = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n\t\t# prepare the image for the VGG model\n\t\timg = preprocess_input(img)\n\t\t# get features\n\t\tfeature = model.predict(img, verbose=0)\n\t\t# get image id\n\t\timg_id = word.split('.')[0]\n\t\t# store feature\n\t\tfeatures[img_id] = feature\n\t\t#print('>%s' % word)\n\treturn features\n \n# extract features from all images\npath = '../input/indian-images/dlcv_indian_images'\n\nimport csv\nwith open('../input/set-files/ic_captions_processed_part_2.csv', mode='r') as infile:\n     reader = csv.reader(infile)\n     valid_files = [row[0] for row in reader]\n\nprint(len(valid_files))\nfeatures = features_extraction(path,valid_files)\nprint('Extracted VGG Features: %d' % len(features))\n# save to file\ndump(features, open('india_2_VGG16features.pkl', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2021-12-14T23:50:10.432634Z","iopub.execute_input":"2021-12-14T23:50:10.432934Z","iopub.status.idle":"2021-12-14T23:50:36.034817Z","shell.execute_reply.started":"2021-12-14T23:50:10.432901Z","shell.execute_reply":"2021-12-14T23:50:36.034048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def LoadDoc(file_name):\n    file = open(file_name, 'r', encoding = \"utf-8\")\n    text_data = file.read()\n    file.close()\n    return text_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def LoadPhotoFeatures(file_name, dataset):\n    AllFeatures = load(open(file_name, 'rb'))\n    features = {k[:-4]: AllFeatures[k[:-4]] for k in dataset}\n    return features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def LoadCleanDescription(file_name):\n  document = LoadDoc(file_name)\n  descriptions = dict()\n  i = 0\n  for l in document.split('\\n'):\n    if len(l)<1:\n      print(l,\":\",i)\n      break\n    i +=1\n    if i == 1:\n      continue\n    tokens = l.split(',')\n    imageId, imageDesc = tokens[0], tokens[1].split()\n    if imageId not in descriptions:\n        descriptions[imageId] = list()\n    desc = 'startseq ' + ' '.join(imageDesc) + ' endseq'\n    descriptions[imageId].append(desc)\n  return descriptions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ToLines(desc):\n    all_desc = list()\n    for key in desc.keys():\n        [all_desc.append(d) for d in desc[key]]\n    return all_desc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2021-12-14T00:49:17.186409Z","iopub.execute_input":"2021-12-14T00:49:17.187125Z","iopub.status.idle":"2021-12-14T00:49:23.810229Z","shell.execute_reply.started":"2021-12-14T00:49:17.187062Z","shell.execute_reply":"2021-12-14T00:49:23.809426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def CreateTokenizer(desc):\n    tokenizer = AutoTokenizer.from_pretrained('monsoon-nlp/hindi-bert')\n    return tokenizer","metadata":{"execution":{"iopub.status.busy":"2021-12-14T00:26:32.25845Z","iopub.execute_input":"2021-12-14T00:26:32.258998Z","iopub.status.idle":"2021-12-14T00:26:32.264653Z","shell.execute_reply.started":"2021-12-14T00:26:32.258953Z","shell.execute_reply":"2021-12-14T00:26:32.263776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def maxLength(descs):\n    lines = ToLines(descs)\n    return max(len(d.split()) for d in lines)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T00:26:44.021754Z","iopub.execute_input":"2021-12-14T00:26:44.022393Z","iopub.status.idle":"2021-12-14T00:26:44.027963Z","shell.execute_reply.started":"2021-12-14T00:26:44.022346Z","shell.execute_reply":"2021-12-14T00:26:44.027109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the captioning model\ndef DefineModel(vocabSize, max_length):\n    inputs1 = Input(shape=(1000,))\n    fe1 = Dropout(0.5, seed = 121)(inputs1)\n    fe2 = Dense(128, activation='relu')(fe1)\n    fe3 = RepeatVector(max_length)(fe2)\n    \n    # embedding\n    inputs2 = Input(shape=(max_length,))\n    emb2 = Embedding(vocab_size, 50, mask_zero=True)(inputs2)\n    emb2a = Dropout(0.5, seed = 121)(emb2)\n    emb3 = LSTM(128, return_sequences=True)(emb2a)\n    emb4 = LSTM(128, return_sequences=True)(emb3)\n    emb5 = TimeDistributed(Dense(128, activation='relu'))(emb4)\n    # merge inputs\n    merged = add([fe3, emb5])\n    # language model (decoder)\n    lm1 = Dropout(0.5, seed = 121)(merged)\n    lm2 = LSTM(500)(lm1)\n    lm3 = Dense(500, activation='relu')(lm2)\n    outputs = Dense(vocab_size, activation='softmax')(lm3)\n    # tie it together [image, seq] [word]\n    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n    model.compile(loss='categorical_crossentropy', optimizer = 'adam' , metrics=['accuracy'])\n    print(model.summary())\n    plot_model(model, show_shapes=True, to_file='plot.png')\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-14T00:26:44.621714Z","iopub.execute_input":"2021-12-14T00:26:44.622Z","iopub.status.idle":"2021-12-14T00:26:44.631761Z","shell.execute_reply.started":"2021-12-14T00:26:44.621966Z","shell.execute_reply":"2021-12-14T00:26:44.630971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['TOKENIZERS_PARALLELISM'] = 'True'","metadata":{"execution":{"iopub.status.busy":"2021-12-14T00:26:46.860556Z","iopub.execute_input":"2021-12-14T00:26:46.861381Z","iopub.status.idle":"2021-12-14T00:26:46.865752Z","shell.execute_reply.started":"2021-12-14T00:26:46.861336Z","shell.execute_reply":"2021-12-14T00:26:46.86449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def CreateSequence(tokenizer, max_length, desc, images, vocabSize):\n    X1, X2, y = list(), list(), list()\n    for key, desc_list in desc.items():\n        #print(key)\n        for desc_sent in desc_list:\n#             print(datetime.now())\n            #print(desc_sent)\n#             sequence = tokenizer.texts_to_sequences([desc_sent])[0]\n            sequence = tokenizer([desc_sent])['input_ids'][0]\n            for i in range(1, len(sequence)):\n                in_sequence, out_sequence = sequence[:i], sequence[i]\n                in_sequence = pad_sequences([in_sequence], maxlen=max_length)[0]\n                out_sequence = to_categorical([out_sequence], num_classes=vocabSize)[0]\n                X1.append(images[key[:-4]][0])\n                X2.append(in_sequence)\n                y.append(out_sequence)\n                # break\n            #break\n        #break\n    return array(X1), array(X2), array(y)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T00:26:47.254871Z","iopub.execute_input":"2021-12-14T00:26:47.255166Z","iopub.status.idle":"2021-12-14T00:26:47.263109Z","shell.execute_reply.started":"2021-12-14T00:26:47.255131Z","shell.execute_reply":"2021-12-14T00:26:47.262011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_descriptions = LoadCleanDescription('/kaggle/input/set-files/train_file.tsv')\n# test_descriptions = LoadCleanDescription('/kaggle/input/setfiles/test_file.tsv')\nvalid_descriptions = LoadCleanDescription('/kaggle/input/set-files/valid_file.tsv')\nprint('Descriptions: train=%d, valid=%d' % (len(train_descriptions), len(valid_descriptions)))","metadata":{"execution":{"iopub.status.busy":"2021-12-14T00:26:52.502692Z","iopub.execute_input":"2021-12-14T00:26:52.503185Z","iopub.status.idle":"2021-12-14T00:26:52.694737Z","shell.execute_reply.started":"2021-12-14T00:26:52.503146Z","shell.execute_reply":"2021-12-14T00:26:52.693733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features = LoadPhotoFeatures('/kaggle/input/set-files/ReNet50features.pkl', train_descriptions)\n# test_features = LoadPhotoFeatures('/kaggle/input/setfiles/ReNet50features.pkl', test_descriptions)\nvalid_features = LoadPhotoFeatures('/kaggle/input/set-files/ReNet50features.pkl', valid_descriptions)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T00:26:52.891926Z","iopub.execute_input":"2021-12-14T00:26:52.892725Z","iopub.status.idle":"2021-12-14T00:26:54.224518Z","shell.execute_reply.started":"2021-12-14T00:26:52.892682Z","shell.execute_reply":"2021-12-14T00:26:54.223723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Photos: train=%d, valid=%d' % (len(train_features), len(valid_features)))","metadata":{"execution":{"iopub.status.busy":"2021-12-14T00:26:54.225992Z","iopub.execute_input":"2021-12-14T00:26:54.22627Z","iopub.status.idle":"2021-12-14T00:26:54.23188Z","shell.execute_reply.started":"2021-12-14T00:26:54.226232Z","shell.execute_reply":"2021-12-14T00:26:54.230982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"tokenizer = CreateTokenizer(train_descriptions)\nvocab_size = len(tokenizer.vocab)+1\nprint('Vocabulary Size: %d' % vocab_size)\n# determine the maximum sequence length\nmax_length = maxLength(train_descriptions)\nprint('Description Length: %d' % max_length)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T00:26:55.819938Z","iopub.execute_input":"2021-12-14T00:26:55.82073Z","iopub.status.idle":"2021-12-14T00:26:56.982769Z","shell.execute_reply.started":"2021-12-14T00:26:55.820678Z","shell.execute_reply":"2021-12-14T00:26:56.981781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = 'Ex18'\nverbose = 2\nn_epochs = 30\nn_photos_per_update = 2\n# n_batches_per_epoch = int(len(train_descriptions.keys()) / n_photos_per_update)\nn_repeats = 5\n\n# for i in range(n_repeats):\nmodel = DefineModel(vocab_size, max_length)\nX1train, X2train, ytrain = CreateSequence(tokenizer, max_length, train_descriptions, train_features, vocab_size)\nX1valid, X2valid, yvalid = CreateSequence(tokenizer, max_length, valid_descriptions, valid_features, vocab_size)\nhist = model.fit([X1train, X2train], ytrain, epochs=10, verbose=2, validation_data=([X1test, X2test], ytest)) \nmodel.save(\"my_model_2\")","metadata":{"execution":{"iopub.status.busy":"2021-12-09T06:53:59.471604Z","iopub.execute_input":"2021-12-09T06:53:59.471994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport keras\n\nclass DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self,ImageFeatures,tokenizer,max_length,descriptions,vocabSize,batch_size=32):\n        'Initialization'\n        self.batch_size = batch_size\n        self.ImageFeatures = ImageFeatures\n        self.tokenizer = tokenizer\n        self.maxLength = max_length\n        self.descriptions = descriptions\n        self.vocabSize = vocabSize\n        self.keys = list(descriptions.keys())\n#         self.X1,self.X2,self.Y = CreateSequence(self.tokenizer, self.maxLength, self.descriptions,self.ImageFeatures,self.vocabSize)\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.descriptions) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        print(datetime.now())\n        batch_keys = self.keys[index*self.batch_size:(index+1)*self.batch_size]\n        batch_descriptions = { your_key: self.descriptions[your_key] for your_key in batch_keys }\n        batch_features = { your_key[:-4]: self.ImageFeatures[your_key[:-4]] for your_key in batch_keys }\n        X1,X2,Y = CreateSequence(self.tokenizer, self.maxLength, batch_descriptions,batch_features,self.vocabSize)\n        X_final = [X1, X2]\n        Y_final = Y\n        return X_final, Y_final\n    \n#     def CreateSequence(tokenizer, maxLength, desc, images, vocabSize):\n#         X1, X2, y = list(), list(), list()\n#         for key, desc_list in desc.items():\n#             #print(key)\n#             for desc_sent in desc_list:\n#                 #print(desc_sent)\n#                 sequence = tokenizer.texts_to_sequences([desc_sent])[0]\n#                 for i in range(1, len(sequence)):\n#                     in_sequence, out_sequence = sequence[:i], sequence[i]\n#                     in_sequence = pad_sequences([in_sequence], maxlen=maxLength)[0]\n#                     out_sequence = to_categorical([out_sequence], num_classes=vocabSize)[0]\n#                     X1.append(images[key[:-4]][0])\n#                     X2.append(in_sequence)\n#                     y.append(out_sequence)\n#                     # break\n#                 #break\n#             #break\n#         return array(X1), array(X2), array(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_generator = DataGenerator(train_features,tokenizer,max_length,train_descriptions,vocab_size)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T00:27:00.569449Z","iopub.execute_input":"2021-12-14T00:27:00.570337Z","iopub.status.idle":"2021-12-14T00:27:00.575165Z","shell.execute_reply.started":"2021-12-14T00:27:00.570285Z","shell.execute_reply":"2021-12-14T00:27:00.574377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = DefineModel(vocab_size, max_length)\nmodel.fit_generator(generator=training_generator,\n                    use_multiprocessing=True,\n                    epochs=20, verbose=2,\n                    workers=6)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T00:27:01.10449Z","iopub.execute_input":"2021-12-14T00:27:01.105385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime","metadata":{"execution":{"iopub.status.busy":"2021-12-14T00:25:18.970996Z","iopub.execute_input":"2021-12-14T00:25:18.971579Z","iopub.status.idle":"2021-12-14T00:25:18.976328Z","shell.execute_reply.started":"2021-12-14T00:25:18.971545Z","shell.execute_reply":"2021-12-14T00:25:18.975465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"my_model_5_captions\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate a description for an image\ndef GenerateDesc(model, tokenizer, image, max_length):\n        start_text = 'startseq'\n        for i in range(max_length):\n                seq = tokenizer.texts_to_sequences([start_text])[0]\n                seq = pad_sequences([seq], maxlen=max_length)\n                yword = model.predict([image,seq], verbose=0,workers=6, use_multiprocessing=True)\n                yword = argmax(yword)\n                word = WordForId(yword, tokenizer)\n                if word is None:\n                        break\n                start_text += ' ' + word\n                if word == 'endseq':\n                        break\n        return start_text\n\n# evaluate the skill of the model\ndef EvaluateModel(model, descs, images, tokenizer, max_length):\n        y, yhat = list(), list()\n        i = 0\n        for key, desc_list in descs.items():\n                print(\"key\",key)\n                yword = GenerateDesc(model, tokenizer, images[key[:-4]], max_length)\n                references = [d.split() for d in desc_list]\n                print(\"yword\",yword)\n                print(\"references\",references)\n                y.append(references)\n                yhat.append(yword.split())\n                if i!=0 and i%20==0:\n                    print('BLEU-1: %f' % corpus_bleu(y, yhat, weights=(1.0, 0, 0, 0)))\n                    break\n                i+=1\n        # calculate BLEU score\n        print('BLEU-1: %f' % corpus_bleu(y, yhat, weights=(1.0, 0, 0, 0)))\n        print('BLEU-2: %f' % corpus_bleu(y, yhat, weights=(0.5, 0.5, 0, 0)))\n        print('BLEU-3: %f' % corpus_bleu(y, yhat, weights=(0.3, 0.3, 0.3, 0)))\n        print('BLEU-4: %f' % corpus_bleu(y, yhat, weights=(0.25, 0.25, 0.25, 0.25)))","metadata":{"execution":{"iopub.status.busy":"2021-12-09T19:10:35.661247Z","iopub.execute_input":"2021-12-09T19:10:35.661915Z","iopub.status.idle":"2021-12-09T19:10:35.675289Z","shell.execute_reply.started":"2021-12-09T19:10:35.661865Z","shell.execute_reply":"2021-12-09T19:10:35.674551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_descriptions = LoadCleanDescription('/kaggle/input/set-files/test_file.tsv')\n# photo features\ntest_features = LoadPhotoFeatures('/kaggle/input/set-files/ReNet50features.pkl', test_descriptions)\n# descriptions","metadata":{"execution":{"iopub.status.busy":"2021-12-09T18:30:34.790725Z","iopub.execute_input":"2021-12-09T18:30:34.79156Z","iopub.status.idle":"2021-12-09T18:30:34.874418Z","shell.execute_reply.started":"2021-12-09T18:30:34.791497Z","shell.execute_reply":"2021-12-09T18:30:34.873727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def WordForId(integer, tokenizer):\n\tfor w, i in tokenizer.word_index.items():\n\t\tif i == integer:\n\t\t\treturn w\n\treturn None","metadata":{"execution":{"iopub.status.busy":"2021-12-09T19:10:37.935706Z","iopub.execute_input":"2021-12-09T19:10:37.93645Z","iopub.status.idle":"2021-12-09T19:10:37.941848Z","shell.execute_reply.started":"2021-12-09T19:10:37.936378Z","shell.execute_reply":"2021-12-09T19:10:37.94077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def DefineModel(vocabSize, maxLength):\n    inputs1 = Input(shape=(1000,))\n    fe1 = Dropout(0.5, seed = 121)(inputs1)\n    fe2 = Dense(128, activation='relu')(fe1)\n    fe3 = RepeatVector(max_length)(fe2)\n    \n    # embedding\n    inputs2 = Input(shape=(max_length,))\n    emb2 = Embedding(vocab_size, 50, mask_zero=True)(inputs2)\n    emb2a = Dropout(0.5, seed = 121)(emb2)\n    emb3 = LSTM(128, return_sequences=True)(emb2a)\n    emb4 = LSTM(128, return_sequences=True)(emb3)\n    emb5 = TimeDistributed(Dense(128, activation='relu'))(emb4)\n    # merge inputs\n    merged = add([fe3, emb5])\n    # language model (decoder)\n    lm1 = Dropout(0.5, seed = 121)(merged)\n    lm2 = LSTM(500)(lm1)\n    lm3 = Dense(500, activation='relu')(lm2)\n    outputs = Dense(vocab_size, activation='softmax')(lm3)\n    # tie it together [image, seq] [word]\n    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n    model.compile(loss='categorical_crossentropy', optimizer = 'adam' , metrics=['accuracy'])\n    print(model.summary())\n    plot_model(model, show_shapes=True, to_file='plot.png')\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-14T00:05:52.233876Z","iopub.execute_input":"2021-12-14T00:05:52.234166Z","iopub.status.idle":"2021-12-14T00:05:52.243561Z","shell.execute_reply.started":"2021-12-14T00:05:52.234133Z","shell.execute_reply":"2021-12-14T00:05:52.242628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_descriptions = LoadCleanDescription('/kaggle/input/set-files/test_file.tsv')\n# photo features\ntest_features = LoadPhotoFeatures('../input/set-files/VGG16features (2).pkl', test_descriptions)\n# descriptions","metadata":{"execution":{"iopub.status.busy":"2021-12-14T00:05:55.178629Z","iopub.execute_input":"2021-12-14T00:05:55.179394Z","iopub.status.idle":"2021-12-14T00:05:55.371605Z","shell.execute_reply.started":"2021-12-14T00:05:55.179355Z","shell.execute_reply":"2021-12-14T00:05:55.370853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"model = load_model(\"/kaggle/input/set-files/vgg16_5_captions\")\n# evaluate model\n","metadata":{"execution":{"iopub.status.busy":"2021-12-09T19:10:52.441798Z","iopub.execute_input":"2021-12-09T19:10:52.44205Z","iopub.status.idle":"2021-12-09T19:10:56.021754Z","shell.execute_reply.started":"2021-12-09T19:10:52.442021Z","shell.execute_reply":"2021-12-09T19:10:56.020947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EvaluateModel(model, test_descriptions, test_features, tokenizer, max_length)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T19:11:26.593302Z","iopub.execute_input":"2021-12-09T19:11:26.593963Z","iopub.status.idle":"2021-12-09T19:11:46.381069Z","shell.execute_reply.started":"2021-12-09T19:11:26.59392Z","shell.execute_reply":"2021-12-09T19:11:46.380367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EvaluateModel(model, test_descriptions, test_features, tokenizer, max_length)\n# resnet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r model_resnet_5_captions_20_epochs.zip my_model_5_captions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EvaluateModel(model, test_descriptions, test_features, tokenizer, max_length)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_descriptions = LoadCleanDescription('/kaggle/input/set-files/test_file.tsv')\n# photo features\ntest_features = LoadPhotoFeatures('/kaggle/input/set-files/ReNet50features.pkl', test_descriptions)\n# descriptions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = load_model(\"/kaggle/input/set-files/resnet_5_captions\")","metadata":{"execution":{"iopub.status.busy":"2021-12-09T18:30:50.593952Z","iopub.execute_input":"2021-12-09T18:30:50.59422Z","iopub.status.idle":"2021-12-09T18:30:55.70332Z","shell.execute_reply.started":"2021-12-09T18:30:50.594189Z","shell.execute_reply":"2021-12-09T18:30:55.702551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nEvaluateModel(model, test_descriptions, test_features, tokenizer, max_length)\n# Resnet full eval\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-09T18:34:34.738608Z","iopub.execute_input":"2021-12-09T18:34:34.739347Z","iopub.status.idle":"2021-12-09T18:34:43.065896Z","shell.execute_reply.started":"2021-12-09T18:34:34.739306Z","shell.execute_reply":"2021-12-09T18:34:43.065185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nvalidation_generator = DataGenerator(valid_features,tokenizer,max_length,valid_descriptions,vocab_size)\nfilename = 'model-ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5'\ncheckpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\nstart = time.time()\nmodel = DefineModel(vocab_size, max_length)\nmodel.fit_generator(generator=training_generator,\n                    validation_data=validation_generator,\n                    use_multiprocessing=True,\n                    epochs=20, verbose=2,\n                    workers=6)\nend = time.time()\nprint(\"TIME TOOK {:3.2f}MIN\".format((end - start )/60))\n    \n#Plot Graph\n\nfor label in [\"loss\",\"val_loss\"]:\n    plt.plot(hist.history[label],label=label)\nplt.legend()\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.show()\nplt.savefig('ModelPerformance.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer(['विकिपीडिया सभी विषयों पर प्रामाणिक और उपयोग, परिवर्तन व पुनर्वितरण के लिए स्वतन्त्र ज्ञानकोश बनाने का एक बहुभाषीय प्रकल्प है।'])['input_ids']","metadata":{"execution":{"iopub.status.busy":"2021-12-14T00:17:02.260748Z","iopub.execute_input":"2021-12-14T00:17:02.261032Z","iopub.status.idle":"2021-12-14T00:17:02.277766Z","shell.execute_reply.started":"2021-12-14T00:17:02.261001Z","shell.execute_reply":"2021-12-14T00:17:02.276972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from indicnlp.tokenize import sentence_tokenize","metadata":{"execution":{"iopub.status.busy":"2021-12-14T00:41:00.72692Z","iopub.execute_input":"2021-12-14T00:41:00.727609Z","iopub.status.idle":"2021-12-14T00:41:00.812038Z","shell.execute_reply.started":"2021-12-14T00:41:00.727493Z","shell.execute_reply":"2021-12-14T00:41:00.81098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def CreateTokenizer():\n    tokenizer = AutoTokenizer.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')\n    return tokenizer","metadata":{"execution":{"iopub.status.busy":"2021-12-14T00:49:37.947665Z","iopub.execute_input":"2021-12-14T00:49:37.948554Z","iopub.status.idle":"2021-12-14T00:49:37.956098Z","shell.execute_reply.started":"2021-12-14T00:49:37.948505Z","shell.execute_reply":"2021-12-14T00:49:37.954803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = CreateTokenizer()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T00:49:39.266607Z","iopub.execute_input":"2021-12-14T00:49:39.267151Z","iopub.status.idle":"2021-12-14T00:49:42.236909Z","shell.execute_reply.started":"2021-12-14T00:49:39.267112Z","shell.execute_reply":"2021-12-14T00:49:42.236068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer(['कहड में चाई और साथ में ब्रेड का टुकड़ा ','विकिपीडिया सभी विषयों पर प्रामाणिक और उपयोग, परिवर्तन व पुनर्वितरण के लिए स्वतन्त्र ज्ञानकोश बनाने का एक बहुभाषीय प्रकल्प है।'])['input_ids']","metadata":{"execution":{"iopub.status.busy":"2021-12-14T00:50:47.435856Z","iopub.execute_input":"2021-12-14T00:50:47.436584Z","iopub.status.idle":"2021-12-14T00:50:47.450454Z","shell.execute_reply.started":"2021-12-14T00:50:47.436535Z","shell.execute_reply":"2021-12-14T00:50:47.449541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:16:08.059022Z","iopub.execute_input":"2021-12-14T22:16:08.059306Z","iopub.status.idle":"2021-12-14T22:16:08.772349Z","shell.execute_reply.started":"2021-12-14T22:16:08.059275Z","shell.execute_reply":"2021-12-14T22:16:08.771252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}